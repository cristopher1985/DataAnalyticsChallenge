{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                    Data Analytics Challenge\n",
    "### por *Cristopher García*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación presentaré el proceso que seguí para completar el reto presentado de realizar un **Análisis de Sentimieto** para visualizar el movimiento de la **Polaridad** en los últimos 9 días en torno a la expresión **\"Panamá\"** con tweets obtenidos accediento al *API* de **Twitter**.  ***¡Reto aceptado!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las Herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La necesidad de extraer datos no-estructurados de manera sistemática desde la web conlleva a usar un lenguaje de programación, por lo que he elegido **R**.  Todo el análisis fue creado en **R Studio** y me apoyé principalmente en las siguientes librerías:  **twitteR** para el web scraping y **ggplot2** (parte de tidyverse) para la visualización.  Las demás librerías ayudan a la manipulación de los datos.  \n",
    "\n",
    "En la siguiente celda puede instalar las librerías requeridas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Instalación de Librerías\n",
    "install.packages(\"twitteR\")\n",
    "install.packages(\"purrr\")\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"ROAuth\")\n",
    "install.packages(\"RCurl\")\n",
    "install.packages(\"stringr\")\n",
    "install.packages(\"tidyverse\")\n",
    "install.packages(\"lubridate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la siguiente celda para cargar las librerías requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Carga de Librerías\n",
    "library(twitteR)\n",
    "library(purrr)\n",
    "library(dplyr)\n",
    "require(\"ROAuth\")\n",
    "require(\"RCurl\")\n",
    "library(plyr)\n",
    "library(stringr)\n",
    "library(tidyverse)\n",
    "library(lubridate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El lexicon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que la función que utilizaremos para evaluar la polaridad de los *tweets* funcione, esta necesita comparar cada palabra con un *lexicon* (listas de palabras positivas y negativas).  Decidí que lo más apropiado sería utilizar uno en español considerando que lo más probable es que la mayoría de los *tweets* en la nación y en la región estarán en este idioma, y por lo que sé, no hay razon para que la comunidad internacional de habla inglesa este conversando sobre nuestro país en estos momentos.\n",
    "\n",
    "En la *web* no pude encontrar un *lexicon* en español pero sí conseguí uno en inglés, publicado por ***Bing Liu, Minqing Hu y Junsheng Cheng***, el cual procedí a traducir.  \n",
    "\n",
    "Descargar los archivos del *lexicon* desde el repositorio y colocarlo en su carpeta de **Jypiter** antes de ejecutar la siguiente celda, la cual cargará el lexicon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## carga del lexicon (cargará siempre que los archivos se encuentren en su directorio de trabajo activo ó working directory)\n",
    "pos.words <- scan(\".//palabras_positivas.txt\", what = \"character\", comment.char = \";\")\n",
    "neg.words <- scan(\".//palabras_negativas.txt\", what = \"character\", comment.char = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La función evaluadora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función, publicada por la plataforma de elearning **edureka!** en su canal de ***Youtube***, es el músculo del código.  Hay muchas otras funciones publicadas de variada complejidad y esta me pareció adecuada por su sencillez y eficacia. La misma evalua la polaridad de un texto despojandolo de carácteres especiales y dígitos, cambiando todas las letras a minúsculas, separándo el texto en palabras individuales, comparándo cada palabra con el lexicon para determinar si la misma es positiva, negativa o neutra, para finalmente hacer una sumatoria y devolver la evalación para todo el texto.  \n",
    "\n",
    "Ejecutar la siguiente celda para cargar la función. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## función de evaluacion de sentimiento\n",
    "score_sentiment<- function(sentences, pos.words, neg.words, .progress=\"none\") \n",
    "{\n",
    "        require(plyr)\n",
    "        require(stringr)\n",
    "        scores <- laply(sentences, function(sentence, pos.words, neg.words){\n",
    "                sentence <- gsub(\"[[:punct:]]\", \"\", sentence)\n",
    "                sentence <- gsub(\"[[:cntrl:]]\", \"\", sentence)\n",
    "                sentence <- gsub(\"\\\\d+\", \"\", sentence)\n",
    "                sentence <- tolower(sentence)\n",
    "                word.list <- str_split(sentence, \"\\\\s+\")\n",
    "                words <- unlist(word.list)\n",
    "                pos.matches <- match(words, pos.words)\n",
    "                neg.matches <- match(words, neg.words)\n",
    "                pos.matches <- !is.na(pos.matches)\n",
    "                neg.matches <- !is.na(neg.matches)\n",
    "                score <- sum(pos.matches) - sum(neg.matches)\n",
    "                return(score)\n",
    "        }, pos.words,neg.words, .progress = .progress)\n",
    "        scores.df <- data.frame(score=scores, text=sentences)\n",
    "        return(scores.df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectando con Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código nos permite conectarnos al *API* de **Twitter** para acceder a la información pública.  Provea los datos de su aplicación en **Twitter** para proseguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conexión al API de Twitter\n",
    "api_key<-\"\"\n",
    "api_secret_key<-\"\"\n",
    "access_token<-\"\"\n",
    "access_token_secret<-\"\"\n",
    "setup_twitter_oauth(api_key,api_secret_key,access_token,access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquí se rompe la reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque los lenguajes de programación nos brindan una mayor capacidad de reproducibilidad que otras herramientas utilizadas para el análisis de datos, el poco control que tenemos sobre la muestra y la limitante que impone **Twitter** para acceder a la data de un máximo de siete días en el pasado, hace que pudieramos obtener resultados ligeramente diferentes cada vez que ejecutemos el código, incluso en un mismo día. \n",
    "\n",
    "Aún así, de querer tener un registro histórico a partir de la fecha se puede correr el código cada día y archivar el resultado.  \n",
    "\n",
    "A continuación definimos las variables de fechas que utilizaremos a partir de la fecha del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables de ultimas 7 fechas\n",
    "hoy <- as.character(Sys.Date())\n",
    "hoym1 <- as.character(Sys.Date()-1)\n",
    "hoym2 <- as.character(Sys.Date()-2)\n",
    "hoym3 <- as.character(Sys.Date()-3)\n",
    "hoym4 <- as.character(Sys.Date()-4)\n",
    "hoym5 <- as.character(Sys.Date()-5)\n",
    "hoym6 <- as.character(Sys.Date()-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apoyándonos en la librería **twitteR** procedemos a obtener los tweets en torno a *#Panama*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#obtencion de los tweets de cada día\n",
    "tweets_hoy <- searchTwitter(\"#Panama\", n=143, since = hoy)\n",
    "tweets_hoym1 <- searchTwitter(\"#Panama\", n=143, since = hoym1 , until = hoy)\n",
    "tweets_hoym2 <- searchTwitter(\"#Panama\", n=143, since = hoym2 , until = hoym1)\n",
    "tweets_hoym3 <- searchTwitter(\"#Panama\", n=143, since = hoym3 , until = hoym2)\n",
    "tweets_hoym4 <- searchTwitter(\"#Panama\", n=143, since = hoym4 , until = hoym3)\n",
    "tweets_hoym5 <- searchTwitter(\"#Panama\", n=143, since = hoym5 , until = hoym4)\n",
    "tweets_hoym6 <- searchTwitter(\"#Panama\", n=143, since = hoym6 , until = hoym5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación procedemos a preparar la data para que sea evaluada por la función principal, hacemos la evaluación y preparamos el resultado para la visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambio de structura de lista a data frame\n",
    "df_hoy <- tbl_df(map_df(tweets_hoy, as.data.frame))\n",
    "df_hoym1 <- tbl_df(map_df(tweets_hoym1, as.data.frame))\n",
    "df_hoym2 <- tbl_df(map_df(tweets_hoym2, as.data.frame))\n",
    "df_hoym3 <- tbl_df(map_df(tweets_hoym3, as.data.frame))\n",
    "df_hoym4 <- tbl_df(map_df(tweets_hoym4, as.data.frame))\n",
    "df_hoym5 <- tbl_df(map_df(tweets_hoym5, as.data.frame))\n",
    "df_hoym6 <- tbl_df(map_df(tweets_hoym6, as.data.frame))\n",
    "\n",
    "\n",
    "#evaluación de sentimiento de los tweets\n",
    "score_hoy <- score_sentiment(df_hoy$text, pos.words, neg.words)\n",
    "score_hoym1<- score_sentiment(df_hoym1$text, pos.words, neg.words)\n",
    "score_hoym2 <- score_sentiment(df_hoym2$text, pos.words, neg.words)\n",
    "score_hoym3 <- score_sentiment(df_hoym3$text, pos.words, neg.words)\n",
    "score_hoym4 <- score_sentiment(df_hoym4$text, pos.words, neg.words)\n",
    "score_hoym5 <- score_sentiment(df_hoym5$text, pos.words, neg.words)\n",
    "score_hoym6 <- score_sentiment(df_hoym6$text, pos.words, neg.words)\n",
    "\n",
    "#integración en data frame único\n",
    "tweets_df <- rbind(df_hoym6,df_hoym5,df_hoym4, df_hoym3, df_hoym2,df_hoym1, df_hoy)\n",
    "scores_df <- rbind(score_hoym6, score_hoym5, score_hoym4, score_hoym3, score_hoym2, score_hoym1, score_hoy)\n",
    "single_df <- cbind(tweets_df[,5], scores_df$score)\n",
    "single_df$Fechasolo <- date(single_df[,1])\n",
    "meanhoy<- mean(score_hoy$score)       \n",
    "meanhoy<- rep(meanhoy, 143)\n",
    "meanhoym1<-mean(score_hoym1$score)\n",
    "meanhoym1<-rep(meanhoym1,143)\n",
    "meanhoym2<-mean(score_hoym2$score)\n",
    "meanhoym2<-rep(meanhoym2, 143)\n",
    "meanhoym3<-mean(score_hoym3$score)\n",
    "meanhoym3<-rep(meanhoym3, 143)\n",
    "meanhoym4<-mean(score_hoym4$score)\n",
    "meanhoym4<-rep(meanhoym4, 143)\n",
    "meanhoym5<-mean(score_hoym5$score)\n",
    "meanhoym5<-rep(meanhoym5, 143)\n",
    "meanhoym6<-mean(score_hoym6$score)\n",
    "meanhoym6<-rep(meanhoym6, 143)\n",
    "meancol<-c(meanhoym6,meanhoym5,meanhoym4, meanhoym3, meanhoym2, meanhoym1, meanhoy)\n",
    "single_df$mean<- meancol\n",
    "names(single_df) <- c(\"Fecha\", \"Score\", \"Fechasolo\", \"Promedio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La presentación de la información la podemos y debemos adecuar a nuestra audiencia.\n",
    "\n",
    "Con la primera visualización pretendo mostrar la información más importante de una manera muy clara y consisa al presentar sólo la polaridad promedio de cada día.  Para ayudar a la comparación de un día a otro se ha agregado una escala de color que inmediatamente muestra el sentimiento general para cada día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(single_df, aes(x=as.factor(Fechasolo), y=Score, color=Promedio)) + scale_color_gradient(low = \"red\", high = \"orange\") + labs(x=\"\", y= \"Polaridad\", title = \"Análisis de Sentimiento\", subtitle = \"'#Panama'\") + geom_boxplot(fill=\"white\",outlier.size = 2,outlier.shape = 21,outlier.fill = \"White\", size=0.9, color=\"white\") + theme_classic() + theme(panel.border = element_rect(fill = NA, color = \"black\", size = 0.8), plot.title = element_text(hjust = 0.5, size = 20) , plot.subtitle = element_text(hjust = 0.5, size = 13), axis.title = element_text(size = 15)) + geom_point(stat = \"summary\", fun=\"mean\", shape= 16, size=20) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica de cajas y bigotes presenta mucha más información sobre nuestros datos que podría ser de interés para un público con más conocimientos estadísticos. \n",
    "\n",
    "El símbolo X en la caja nos muestra la polaridad promedio para cada día y sólo con eso cualquier persona puede tener una buena idea de como se ha movido la polaridad a través de los últimos siete días.  Así mismo tenemos una mejor visión de la variabilidad en la data y de las observaciones atípicas (*outliers*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_base <- ggplot(single_df, aes(x=as.factor(Fechasolo), y=Score)) + geom_boxplot()\n",
    "vis_base + labs(x=\"\", y= \"Polaridad\", title = \"Análisis de Sentimiento\", subtitle = \"'#Panama'\") + geom_boxplot(fill=1300,outlier.size = 2,outlier.shape = 21,outlier.fill = \"White\", size=0.9) + theme_bw() + theme(panel.border = element_rect(fill = NA, color = \"black\", size = 0.8), plot.title = element_text(hjust = 0.5, size = 20) , plot.subtitle = element_text(hjust = 0.5, size = 13), axis.title = element_text(size = 15)) + geom_point(stat = \"summary\", fun= \"mean\", shape= 4, size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La data muestra que el sentimiento en torno a ***#Panamá*** varía entre neutral a negativo, algo que hace mucho sentido dada la realidad de los efectos del COVID-19, la tragedia en tierras altas, y hasta el mal resultado deportivo ante **Estados Unidos**.\n",
    "\n",
    "Espero que el día de la entrevista técnica podamos ver resultamos un poco más positivos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edureka!. Sentiment Analysis in R | Sentiment Analysis of Twitter Data | Data Science Training. https://www.youtube.com/watch?v=-JW6_kcHDj4&t=2285s\n",
    "\n",
    "Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\"\n",
    "\n",
    "Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing and Comparing Opinions on the Web.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
